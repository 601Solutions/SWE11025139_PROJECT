import pandas as pd
from langchain.schema import Document
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import OpenAI

# --- 1ë‹¨ê³„: ë°ì´í„° ë¡œë”© ë° 'ì§€ì‹'ìœ¼ë¡œ ë³€í™˜ ---
try:
    df = pd.read_csv('lifet_products_cleaned.csv')
    print("âœ… ì •ì œëœ CSV íŒŒì¼ ë¡œë”© ì„±ê³µ!")

    # ê° í–‰ì„ LangChainì´ ì‚¬ìš©í•˜ëŠ” Document ê°ì²´ë¡œ ë³€í™˜
    # page_contentì— LLMì´ ì´í•´í•  ìì—°ì–´ ë¬¸ì¥ì„ ë„£ëŠ” ê²ƒì´ í•µì‹¬
    documents = []
    for index, row in df.iterrows():
        content = f"ìƒí’ˆëª…ì€ '{row['NAME']}'ì´ê³ , ê°€ê²©ì€ {row['PRICE']}ì›ì…ë‹ˆë‹¤."
        doc = Document(page_content=content)
        documents.append(doc)
    
    print(f"âœ… {len(documents)}ê°œì˜ ìƒí’ˆ ì •ë³´ë¥¼ Documentë¡œ ë³€í™˜ ì™„ë£Œ!")
    # print("Document ì˜ˆì‹œ:", documents[0]) # ì²« ë²ˆì§¸ Document ë‚´ìš© í™•ì¸

except FileNotFoundError:
    print("âŒ ì˜¤ë¥˜: 'lifet_products_cleaned.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()


# --- 2ë‹¨ê³„: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ---
# í•œêµ­ì–´ ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ë¡œë”© (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
print("ì„ë² ë”© ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
model_name = "jhgan/ko-sbert-nli"
model_kwargs = {'device': 'cpu'}
encode_kwargs = {'normalize_embeddings': True}
embeddings = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)
print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# Documentë“¤ì„ ë²¡í„°í™”í•˜ì—¬ FAISS ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶• ì¤‘ì…ë‹ˆë‹¤...")
vectorstore = FAISS.from_documents(documents, embeddings)
print("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ!")


# --- 3ë‹¨ê³„: ì§ˆì˜ì‘ë‹µ(QA) ì‹œìŠ¤í…œ êµ¬í˜„ ---
# OpenAI LLM ëª¨ë¸ ë¡œë”© (í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨)
try:
    llm = OpenAI(temperature=0) # temperature=0ì€ ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ë†’ì—¬ì¤Œ
    print("âœ… OpenAI LLM ë¡œë”© ì„±ê³µ!")
except Exception as e:
    print(f"âŒ OpenAI LLM ë¡œë”© ì‹¤íŒ¨: API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {e})")
    exit()

# RAG ì²´ì¸ ìƒì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever()
)
print("âœ… QA ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")

# --- ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ---
question = "ì•„ì¸ì† ê°•ì•„ì§€ ë¹„ëˆ„ ê°€ê²© ì•Œë ¤ì¤˜"
print(f"\nğŸ’¬ ì§ˆë¬¸: {question}")

# ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
response = qa_chain.invoke(question)

print(f"ğŸ¤– ë‹µë³€: {response['result']}")